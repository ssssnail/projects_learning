{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc_dir = 'D:\\\\udacity\\\\homework\\\\fast-style-transfer'\n",
    "\n",
    "STYLE = 'style2'\n",
    "CONTENT = 'content5'\n",
    "#style_reference_image_path = loc_dir+'/styles/' + STYLE + '.jpg'\n",
    "style_reference_image_path = './' + STYLE + '.jpg'\n",
    "#base_image_path = loc_dir+'/content/' + CONTENT + '.jpg'\n",
    "base_image_path =  './' + CONTENT + '.jpg'\n",
    "#result_prefix = loc_dir+'/transfer_pic/'\n",
    "result_prefix = './'\n",
    "content_weight = 0.025\n",
    "style_weight = 1.5\n",
    "tv_weight = 1.0\n",
    "total_variation_weight = 1.0\n",
    "\n",
    "\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    #使用Keras内置函数读入图片，由于网络没有全连阶层，target_size可以随便设。\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols)) \n",
    "    #读入的图片用内置函数转换为numpy array格式，这两个函数都在keras.preprocessing.image里\n",
    "    img = img_to_array(img) \n",
    "    #：维度扩展，这步在Keras用于图像处理中也很常见，Keras的彩色图输入shape是四阶张量，第一阶是batch_size。\n",
    "    #而裸读入的图片是3阶张量。为了匹配，需要通过维度扩展扩充为四阶，第一阶当然就是1了。\n",
    "    img = np.expand_dims(img, axis=0) #3\n",
    "    #vgg提供的预处理，主要完成（1）去均值（2）RGB转BGR（3）维度调换三个任务。\n",
    "    #去均值是vgg网络要求的，RGB转BGR是因为这个权重是在caffe上训练的，caffe的彩色维度顺序是BGR。\n",
    "    #维度调换是要根据系统设置的维度顺序th/tf将通道维调到正确的位置，如th的通道维应为第二维\n",
    "    img = vgg19.preprocess_input(img) \n",
    "    return img\n",
    "\n",
    "#可以看到，后处理的567三个步骤主要就是将#4的预处理反过来了，这是为了将处理过后的图片显示出来，resonable。\n",
    "def deprocess_image(x):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.reshape((3, img_nrows, img_ncols))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((img_nrows, img_ncols, 3)) \n",
    "   \n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68 \n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8') \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入内容和风格图，包装为Keras张量，这是一个常数的四阶张量\n",
    "base_image = K.variable(preprocess_image(base_image_path)) \n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path)) \n",
    "\n",
    "#初始化一个待优化图片的占位符，这个地方待会儿实际跑起来的时候要填一张噪声图片进来。\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n",
    "else:\n",
    "    combination_image = K.placeholder((1, img_nrows, img_ncols, 3)) \n",
    "\n",
    "#将三个张量串联到一起，形成一个形如（3,3,img_nrows,img_ncols）的张量\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "combination_image], axis=0) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = vgg19.VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置Gram矩阵的计算图，首先用batch_flatten将输出的featuremap压扁，然后自己跟自己做乘法，跟我们之前说过的过程一样。注意这里的输入是某一层的representation。\n",
    "def gram_matrix(x): \n",
    "    assert K.ndim(x) == 3\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        features = K.batch_flatten(x)\n",
    "    else:\n",
    "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "#设置风格loss计算方式，以风格图片和待优化的图片的representation为输入。\n",
    "#计算他们的Gram矩阵，然后计算两个Gram矩阵的差的二范数，除以一个归一化值，公式请参考文献[1]\n",
    "def style_loss(style, combination): #2\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "#设置内容loss计算方式，以内容图片和待优化的图片的representation为输入，计算他们差的二范数，公式参考文献[1]\n",
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n",
    "\n",
    "#施加全变差正则，全变差正则用于使生成的图片更加平滑自然。\n",
    "def total_variation_loss(x): \n",
    "    assert K.ndim(x) == 4\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        a = K.square(x[:, :, :img_nrows-1, :img_ncols-1] - x[:, :, 1:, :img_ncols-1])\n",
    "        b = K.square(x[:, :, :img_nrows-1, :img_ncols-1] - x[:, :, :img_nrows-1, 1:])\n",
    "    else:\n",
    "        a = K.square(x[:, :img_nrows-1, :img_ncols-1, :] - x[:, 1:, :img_ncols-1, :])\n",
    "        b = K.square(x[:, :img_nrows-1, :img_ncols-1, :] - x[:, :img_nrows-1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这是一个张量字典，建立了层名称到层输出张量的映射，通过这个玩意我们可以通过层的名字来获取其输出张量，比较方便。当然不用也行，使用model.get_layer(layer_name).output的效果也是一样的。\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers]) \n",
    "\n",
    "#loss的值是一个浮点数，所以我们初始化一个标量张量来保存它\n",
    "loss = K.variable(0.) \n",
    "\n",
    "#layer_features就是图片在模型的block4_conv2这层的输出了，记得我们把输入做成了(3,3,nb_rows,nb_cols)这样的张量，\n",
    "#0号位置对应内容图像的representation，1号是风格图像的，2号位置是待优化的图像的。计算内容loss取内容图像和待优化图像即可\n",
    "layer_features = outputs_dict['block4_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :] \n",
    "loss += content_weight * content_loss(base_image_features,\n",
    "                                      combination_features) \n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "#与上面的过程类似，只是对多个层的输出作用而已，求出各个层的风格loss，相加即可。\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss += (style_weight / len(feature_layers)) * sl \n",
    "\n",
    "#求全变差约束，加入总loss中\n",
    "loss += total_variation_weight * total_variation_loss(combination_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过K.grad获取反传梯度\n",
    "grads = K.gradients(loss, combination_image) \n",
    "\n",
    "outputs = [loss]\n",
    "#我们希望同时得到梯度和损失，所以这两个都应该是计算图的输出\n",
    "if type(grads) in {list, tuple}:\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads) \n",
    "#编译计算图。Amazing！我们写了辣么多辣么多代码，其实都在规定输入输出的计算关系，到这里才将计算图编译了。\n",
    "#这条语句以后，f_outputs就是一个可用的Keras函数，给定一个输入张量，就能获得其反传梯度了。\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self):\n",
    "        # 这个类别的事不干，专门保存损失值和梯度值\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        # 调用刚才写的那个函数同时得到梯度值和损失值，但只返回损失值，而将梯度值保存在成员变量self.grads_values中，这样这个函数就满足了func要求的条件\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        # 这个函数不用做任何计算，只需要把成员变量self.grads_values的值返回去就行了\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((1, 3, img_nrows, img_ncols))\n",
    "    else:\n",
    "        x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 2.97019e+10\n",
      "Image saved as ./_at_iteration_0.png\n",
      "Start of iteration 1\n",
      "Start of iteration 2\n",
      "Current loss value: 1.33003e+10\n",
      "Image saved as ./_at_iteration_2.png\n",
      "Start of iteration 3\n",
      "Start of iteration 4\n",
      "Current loss value: 1.05866e+10\n",
      "Image saved as ./_at_iteration_4.png\n",
      "Start of iteration 5\n",
      "Start of iteration 6\n",
      "Current loss value: 9.6429e+09\n",
      "Image saved as ./_at_iteration_6.png\n",
      "Start of iteration 7\n",
      "Start of iteration 8\n",
      "Current loss value: 9.17949e+09\n",
      "Image saved as ./_at_iteration_8.png\n",
      "Start of iteration 9\n",
      "Start of iteration 10\n",
      "Current loss value: 8.92649e+09\n",
      "Image saved as ./_at_iteration_10.png\n",
      "Start of iteration 11\n",
      "Start of iteration 12\n",
      "Current loss value: 8.75046e+09\n",
      "Image saved as ./_at_iteration_12.png\n",
      "Start of iteration 13\n",
      "Start of iteration 14\n",
      "Current loss value: 8.63603e+09\n",
      "Image saved as ./_at_iteration_14.png\n",
      "Start of iteration 15\n",
      "Start of iteration 16\n",
      "Current loss value: 8.54478e+09\n",
      "Image saved as ./_at_iteration_16.png\n",
      "Start of iteration 17\n",
      "Start of iteration 18\n",
      "Current loss value: 8.47532e+09\n",
      "Image saved as ./_at_iteration_18.png\n",
      "Start of iteration 19\n",
      "Start of iteration 20\n",
      "Current loss value: 8.41646e+09\n",
      "Image saved as ./_at_iteration_20.png\n",
      "Start of iteration 21\n",
      "Start of iteration 22\n",
      "Current loss value: 8.36995e+09\n",
      "Image saved as ./_at_iteration_22.png\n",
      "Start of iteration 23\n",
      "Start of iteration 24\n",
      "Current loss value: 8.32983e+09\n",
      "Image saved as ./_at_iteration_24.png\n",
      "Start of iteration 25\n",
      "Start of iteration 26\n",
      "Current loss value: 8.29465e+09\n",
      "Image saved as ./_at_iteration_26.png\n",
      "Start of iteration 27\n",
      "Start of iteration 28\n",
      "Current loss value: 8.2584e+09\n",
      "Image saved as ./_at_iteration_28.png\n",
      "Start of iteration 29\n",
      "Start of iteration 30\n",
      "Current loss value: 8.22813e+09\n",
      "Image saved as ./_at_iteration_30.png\n",
      "Iteration 30 completed in 10s\n"
     ]
    }
   ],
   "source": [
    "# 根据后端初始化一张噪声图片，做去均值\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\n",
    "else:\n",
    "    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128. \n",
    "\n",
    "# 迭代10次\n",
    "for i in range(31):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    # 这里用了一个奇怪的函数 fmin_l_bfgs_b更新x，我们一会再看它，这里知道它的作用是更新x就好\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20) \n",
    "    if i % 2 == 0:\n",
    "        print('Current loss value:', min_val)\n",
    "        # save current generated image\n",
    "        # 每次迭代完成后把输出的图片后处理一下，保存起来\n",
    "        img = deprocess_image(x.copy()) \n",
    "        fname = result_prefix + '_at_iteration_%d.png' % i\n",
    "        #imsave(fname, img) #4\n",
    "    \n",
    "        scipy.misc.imsave(fname,img)\n",
    "        end_time = time.time()\n",
    "        print('Image saved as', fname)\n",
    "print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
