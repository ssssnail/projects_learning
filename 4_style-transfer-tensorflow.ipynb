{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\udacity\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "#工具包所用的库\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "因为加载的模型是mat形式，用scipy.io读取后是numpy的形式，需要进行转换\n",
    "首先我们要知道需要提取的参数有卷积+relu层和池化层的参数\n",
    "这一个cell的程序都是模型转换的部分\n",
    "'''\n",
    "\n",
    "# 权重提取函数,返回权重的值\n",
    "def _weight(vgg_layers, layer, expected_layer_name):\n",
    "    W = vgg_layers[0][layer][0][0][2][0][0]\n",
    "    b = vgg_layers[0][layer][0][0][2][0][1]\n",
    "    layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "    assert layer_name == expected_layer_name\n",
    "    return W,b.reshape(b.size) #原来b是个列向量\n",
    "# 提取卷积层参数，即filter的权重\n",
    "def _conv2d_relu(vgg_layers, prev_layer, layer, layer_name):\n",
    "    '''\n",
    "      函数目的是返回这一层使用的filter的权重和bias\n",
    "      输入：\n",
    "         vgg_layers: VGGNet的所有层\n",
    "         prev_layer: 前一层的输出tensor\n",
    "         layer: 当前层的index，这个是由使用的VGG模型决定的\n",
    "         layer_name: 当前层使用的名字，这个用于指定变量空间\n",
    "     输出：\n",
    "         relu的结果\n",
    "    '''\n",
    "    with tf.variable_scope(layer_name) as scope:\n",
    "        W, b = _weight(vgg_layers, layer, layer_name)\n",
    "        W = tf.constant(W, name='weights')\n",
    "        b = tf.constant(b, name='bias')\n",
    "        conv2d = tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv2d + b)\n",
    "def _avgpool(prev_layer):\n",
    "    \"\"\"\n",
    "    实现平均池化层\n",
    "    Input:\n",
    "        prev_layer: 前一层的输出\n",
    "\n",
    "    Output:\n",
    "        平均池化结果\n",
    "    Hint for choosing strides and kszie: choose what you feel appropriate\n",
    "    \"\"\"\n",
    "    return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                          padding='SAME', name='avg_pool_')\n",
    "def load_vgg(path, input_image):\n",
    "    '''\n",
    "    函数用于转换VGG为TensorFlow，用一个dict来保存模型。\n",
    "    想要更好的理解这一部分需要了解.mat文件的内容结构和VGGNet-16的结构\n",
    "    需要注意matlab里是从1开始的而Python是从0开始的，所以用matlab打开VGG的时候一下关于层数之类的数量可能会差1\n",
    "    '''\n",
    "    vgg = scipy.io.loadmat(path)#读取文件\n",
    "    vgg_layers = vgg['layers'] #读取文件中layer下的的值\n",
    "    \n",
    "    graph = {} \n",
    "    graph['conv1_1']  = _conv2d_relu(vgg_layers, input_image, 0, 'conv1_1')#第一部分的卷积1\n",
    "    graph['conv1_2']  = _conv2d_relu(vgg_layers, graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(vgg_layers, graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(vgg_layers, graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(vgg_layers, graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(vgg_layers, graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(vgg_layers, graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(vgg_layers, graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(vgg_layers, graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(vgg_layers, graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(vgg_layers, graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(vgg_layers, graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(vgg_layers, graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(vgg_layers, graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(vgg_layers, graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(vgg_layers, graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的三个函数都是为了能从现有的模型中提取出参数，下面就到了正式实现的时候了\n",
    "首先是需要常量的赋值和损失函数的计算\n",
    "\n",
    "计算content_loss\n",
    "计算syle_loss\n",
    "总的损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(download_link, file_name, expected_bytes):\n",
    "    \"\"\" Download the pretrained VGG-19 model if it's not already downloaded \"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        print(\"Dataset ready\")\n",
    "        return\n",
    "    print(\"Downloading the VGG pre-trained model. This might take a while ...\")\n",
    "    file_name, _ = urllib.request.urlretrieve(download_link, file_name)\n",
    "    file_stat = os.stat(file_name)\n",
    "    if file_stat.st_size == expected_bytes:\n",
    "        print('Successfully downloaded the file', file_name)\n",
    "    else:\n",
    "        raise Exception('File ' + file_name +\n",
    "                        ' might be corrupted. You should try downloading it with a browser.')\n",
    "\n",
    "def get_resized_image(img_path, height, width, save=True):\n",
    "    image = Image.open(img_path)\n",
    "    # it's because PIL is column major so you have to change place of width and height\n",
    "    # this is stupid, i know\n",
    "    image = ImageOps.fit(image, (width, height), Image.ANTIALIAS)\n",
    "    image = image.convert('RGB')\n",
    "    if save:\n",
    "        image_dirs = img_path.split('/')\n",
    "        image_dirs[-1] = 'resized_' + image_dirs[-1]\n",
    "        out_path = '/'.join(image_dirs)\n",
    "        if not os.path.exists(out_path):\n",
    "            image.save(out_path)\n",
    "    image = np.asarray(image, np.float32)\n",
    "    return np.expand_dims(image, 0)\n",
    "\n",
    "def generate_noise_image(content_image, height, width, noise_ratio=0.6):\n",
    "    noise_image = np.random.uniform(-20, 20, \n",
    "                                    (1, height, width, 3)).astype(np.float32)\n",
    "    return noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "\n",
    "def save_image(path, image):\n",
    "    # Output should add back the mean pixels we subtracted at the beginning\n",
    "    image = image[0] # the image\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先需要定义需要的常量\n",
    "loc_dir = 'D:\\\\udacity\\\\homework\\\\fast-style-transfer'\n",
    "\n",
    "STYLE = 'style2'\n",
    "CONTENT = 'content2'\n",
    "STYLE_IMAGE = loc_dir+'/styles/' + STYLE + '.jpg'\n",
    "CONTENT_IMAGE = loc_dir+'/content/' + CONTENT + '.jpg'\n",
    "\n",
    "IMAGE_HEIGHT = 250 #图像尺寸\n",
    "IMAGE_WIDTH = 333\n",
    "\n",
    "NOISE_RATIO = 0.6 # 生成噪声图像时用的\n",
    "\n",
    "CONTENT_WEIGHT = 0.5 #content和style的权重，可以随意调整\n",
    "STYLE_WEIGHT = 1\n",
    "\n",
    "#style的一些参考层，和每一层的权重，层数越深对style的影响越大，这个是可以随意调整的\n",
    "STYLE_LAYERS = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "W = [0.5, 1.0, 1.5, 3.0, 4.0] \n",
    "#content的参考层，可以随意调整\n",
    "CONTENT_LAYER = 'conv4_2'\n",
    "\n",
    "learning_rate = 5#学习率\n",
    "STEPS = 600 #step的次数\n",
    "\n",
    "# MEAN_PIXELS这个和我们用的VGG模型有关，它在训练的时候是减去均值训练的，所以这里我们也是需要在训练的时候减去均值\n",
    "# 不过这样肯定会影响构造出的图像的效果\n",
    "MEAN_PIXELS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "VGG_MODEL = 'imagenet-vgg-verydeep-19.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#现在就可以开始计算loss了\n",
    "#首先是content_loss\n",
    "def _create_content_loss(p, f):\n",
    "    '''\n",
    "    计算内容损失函数\n",
    "    输入：\n",
    "        p和f分别为每一层输出的激活值\n",
    "        f为生成图片的特征表示，p是content图片的特征表示\n",
    "    输出：\n",
    "        content_loss\n",
    "    '''\n",
    "    #这里有一点注意的是，loss的计算方法和paper中的计算不同，paper中损失函数的收敛速度过慢了，\n",
    "    # 所以把1/2编程1/(4s),s为p的维度的乘积\n",
    "    return tf.reduce_sum((f - p)**2)/(4.0 * p.size)\n",
    "\n",
    "def _gram_matrix(F, N, M):\n",
    "    '''\n",
    "    计算gram矩阵\n",
    "    输入：\n",
    "        F为图片在某一层通过某个filter后的激活值(第一个维度为输入图片数量等于1)\n",
    "        N为特征map的第四个维度（filter数量）\n",
    "        M为每个filter的维度乘积\n",
    "    输出：\n",
    "        gram矩阵的值\n",
    "    '''\n",
    "    F = tf.reshape(F,(M,N))\n",
    "    return tf.matmul(tf.transpose(F), F)\n",
    "def _single_style_loss(a, g):\n",
    "    \"\"\" 计算某一层的style损失\n",
    "    Inputs:\n",
    "        a 真实图片的特征表示\n",
    "        g 生产图片的特征表示\n",
    "    Output:\n",
    "        某一层的style损失\n",
    "\n",
    "    Hint: 1. you'll have to use the function _gram_matrix()\n",
    "        2. we'll use the same coefficient for style loss as in the paper\n",
    "        3. a and g are feature representation, not gram matrices\n",
    "    \"\"\"\n",
    "    N = a.shape[3]\n",
    "    M = a.shape[1]*a.shape[2]\n",
    "    A = _gram_matrix(a, N, M)\n",
    "    G = _gram_matrix(g, N, M)\n",
    "    return tf.reduce_sum((G-A)**2)/((2.0*N*M)**2)\n",
    "\n",
    "def _style_loss(A, model):\n",
    "    '''\n",
    "    计算总的style损失\n",
    "    输入：\n",
    "        A 真实图片的在各指定层的特征表示\n",
    "        model 生成图片在各层的生产结果（把所有层的结果都放进来了）\n",
    "    输出：\n",
    "        各层的损失和\n",
    "    '''\n",
    "    num_layer = len(STYLE_LAYERS)\n",
    "    E = [_single_style_loss(A[i],model[STYLE_LAYERS[i]]) for i in range(num_layer)]\n",
    "    return sum([W[i]*E[i] for i in range(num_layer)])\n",
    "\n",
    "def _creat_loss(model, input_image, content_image, style_image):\n",
    "    '''\n",
    "    计算总的损失函数值,这里还是有点绕的，需要对Session理解的够透彻,重复用了图的某一个部分\n",
    "    输入：\n",
    "        model：VGG模型\n",
    "        输入的三个原图像\n",
    "    输出：\n",
    "        总的损失和\n",
    "    '''\n",
    "    with tf.variable_scope('loss') as scope:\n",
    "        with tf.Session() as sess:\n",
    "            #这个sess用于计算content image在某层的输出结果\n",
    "            sess.run(input_image.assign(content_image))#赋值操作\n",
    "            p = sess.run(model[CONTENT_LAYER])#计算content image 在给定层的输出值\n",
    "        content_loss = _create_content_loss(p, model[CONTENT_LAYER])\n",
    "        #同理计算style_loss\n",
    "        with tf.Session() as sess:\n",
    "            #这个sess用于计算style image在某几层的输出结果\n",
    "            sess.run(input_image.assign(style_image))#赋值操作\n",
    "            p = sess.run([model[layers] for layers in STYLE_LAYERS])#这里注意一下\n",
    "        style_loss = _style_loss(p, model)\n",
    "        \n",
    "        #计算总的损失\n",
    "        total_loss = CONTENT_WEIGHT * content_loss + STYLE_WEIGHT * style_loss\n",
    "    return content_loss, style_loss, total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在定义完损失函数之后，需要定义需要summary的函数用于在TensorBoard上可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_summary(model):\n",
    "    with tf.name_scope('summaries'):\n",
    "        tf.summary.scalar('content_loss', model['content_loss'])\n",
    "        tf.summary.scalar('style_loss', model['style_loss'])\n",
    "        tf.summary.scalar('total_loss', model['total_loss'])\n",
    "        tf.summary.histogram('histogram_content_loss', model['content_loss'])\n",
    "        tf.summary.histogram('histogram_style_loss', model['style_loss'])\n",
    "        tf.summary.histogram('histogram_total_loss', model['total_loss'])\n",
    "        return tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里是总的搭建图的函数流程，调用上面的函数构成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入变量,这里把输入也变为了一个变量节点，可以进行传播求导\n",
    "with tf.variable_scope('input') as scope:\n",
    "    #注意这里是变量，这个就有点类似于用变量表达Placeholder的感觉，因为后面都在给input_image赋值\n",
    "    input_image = tf.Variable(np.zeros([1, IMAGE_HEIGHT, IMAGE_WIDTH, 3]),dtype=tf.float32)\n",
    "    \n",
    "#读取图像和VGG模型(注意这些现在还都是在构造图)\n",
    "model = load_vgg(VGG_MODEL, input_image)#构造模型\n",
    "model['global_step'] = tf.Variable(0, dtype=tf.int32,trainable=False, name='global_step' )#这个为了用于观察过程中的图片生产效果\n",
    "\n",
    "#对输入的图像进行一些处理，如尺度变换\n",
    "content_image = get_resized_image(CONTENT_IMAGE, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "content_image = content_image - MEAN_PIXELS\n",
    "style_image = get_resized_image(STYLE_IMAGE, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "style_image = style_image - MEAN_PIXELS\n",
    "\n",
    "\n",
    "#定义计算损失值\n",
    "model['content_loss'], model['style_loss'], model['total_loss'] = _creat_loss(model, input_image, content_image, style_image)\n",
    "#设计优化函数\n",
    "model['optimizer'] = tf.train.AdagradOptimizer(learning_rate).minimize(model['total_loss'])\n",
    "#设计summary用于TensorBoard展示\n",
    "model['summary_op'] = _create_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面已经把图都已经搭建完成，现在要做的就是运行图，得到最后生成的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\udacity\\homework\\fast-style-transfer/checkpoints/style_transfer-599\n",
      "Step 1\n",
      "   Sum: 28671012.0\n",
      "   Loss: 7445566976.0\n",
      "   Time: 21.39522385597229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\udacity\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:39: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n",
      "   Sum: 28668225.8\n",
      "   Loss: 7411749376.0\n",
      "   Time: 4.888279676437378\n",
      "Step 3\n",
      "   Sum: 28662318.6\n",
      "   Loss: 7307680256.0\n",
      "   Time: 5.468312740325928\n",
      "Step 4\n",
      "   Sum: 28655269.6\n",
      "   Loss: 7052082176.0\n",
      "   Time: 5.4443113803863525\n",
      "Step 5\n",
      "   Sum: 28647017.2\n",
      "   Loss: 6559699968.0\n",
      "   Time: 5.667324066162109\n",
      "Step 10\n",
      "   Sum: 28617033.6\n",
      "   Loss: 3671993600.0\n",
      "   Time: 19.901138305664062\n",
      "Step 20\n",
      "   Sum: 28592287.0\n",
      "   Loss: 1725295360.0\n",
      "   Time: 38.06517720222473\n",
      "Step 40\n",
      "   Sum: 28583932.0\n",
      "   Loss: 957194496.0\n",
      "   Time: 82.72573161125183\n",
      "Step 60\n",
      "   Sum: 28583966.2\n",
      "   Loss: 701292480.0\n",
      "   Time: 101.50380563735962\n",
      "Step 80\n",
      "   Sum: 28582329.2\n",
      "   Loss: 557461760.0\n",
      "   Time: 108.73821949958801\n",
      "Step 100\n",
      "   Sum: 28579757.1\n",
      "   Loss: 463515136.0\n",
      "   Time: 107.74616289138794\n",
      "Step 120\n",
      "   Sum: 28578089.9\n",
      "   Loss: 396171744.0\n",
      "   Time: 110.41631531715393\n",
      "Step 140\n",
      "   Sum: 28577240.7\n",
      "   Loss: 346138048.0\n",
      "   Time: 112.391428232193\n",
      "Step 160\n",
      "   Sum: 28576945.3\n",
      "   Loss: 307522336.0\n",
      "   Time: 110.59132552146912\n",
      "Step 180\n",
      "   Sum: 28576981.3\n",
      "   Loss: 277033280.0\n",
      "   Time: 111.23536229133606\n",
      "Step 200\n",
      "   Sum: 28577355.2\n",
      "   Loss: 252371712.0\n",
      "   Time: 114.37154150009155\n",
      "Step 220\n",
      "   Sum: 28577946.8\n",
      "   Loss: 231884816.0\n",
      "   Time: 113.54749464988708\n",
      "Step 240\n",
      "   Sum: 28578870.9\n",
      "   Loss: 214678096.0\n",
      "   Time: 110.50132060050964\n",
      "Step 260\n",
      "   Sum: 28579877.6\n",
      "   Loss: 200032224.0\n",
      "   Time: 114.67255878448486\n",
      "Step 280\n",
      "   Sum: 28580901.7\n",
      "   Loss: 187317136.0\n",
      "   Time: 115.2675929069519\n",
      "Step 300\n",
      "   Sum: 28581836.0\n",
      "   Loss: 176227680.0\n",
      "   Time: 113.41048669815063\n",
      "Step 320\n",
      "   Sum: 28582737.7\n",
      "   Loss: 166543248.0\n",
      "   Time: 110.57332420349121\n",
      "Step 340\n",
      "   Sum: 28583601.1\n",
      "   Loss: 157989472.0\n",
      "   Time: 113.11446976661682\n",
      "Step 360\n",
      "   Sum: 28584234.9\n",
      "   Loss: 150368480.0\n",
      "   Time: 114.66055822372437\n",
      "Step 380\n",
      "   Sum: 28584718.5\n",
      "   Loss: 143539712.0\n",
      "   Time: 114.31353855133057\n",
      "Step 400\n",
      "   Sum: 28585099.5\n",
      "   Loss: 137365504.0\n",
      "   Time: 113.68050241470337\n",
      "Step 420\n",
      "   Sum: 28585316.0\n",
      "   Loss: 131733000.0\n",
      "   Time: 114.64055681228638\n",
      "Step 440\n",
      "   Sum: 28585411.6\n",
      "   Loss: 126582048.0\n",
      "   Time: 111.56538128852844\n",
      "Step 460\n",
      "   Sum: 28585367.6\n",
      "   Loss: 121835584.0\n",
      "   Time: 115.51060676574707\n",
      "Step 480\n",
      "   Sum: 28585192.1\n",
      "   Loss: 117436992.0\n",
      "   Time: 120.26287889480591\n",
      "Step 500\n",
      "   Sum: 28584926.4\n",
      "   Loss: 113362552.0\n",
      "   Time: 119.96486139297485\n",
      "Step 520\n",
      "   Sum: 28584581.7\n",
      "   Loss: 109564296.0\n",
      "   Time: 115.93963122367859\n",
      "Step 540\n",
      "   Sum: 28584155.3\n",
      "   Loss: 106026664.0\n",
      "   Time: 118.85879850387573\n",
      "Step 560\n",
      "   Sum: 28583638.3\n",
      "   Loss: 102707168.0\n",
      "   Time: 112.99146270751953\n",
      "Step 580\n",
      "   Sum: 28583022.3\n",
      "   Loss: 99580744.0\n",
      "   Time: 118.55478072166443\n",
      "Step 600\n",
      "   Sum: 28582309.3\n",
      "   Loss: 96648552.0\n",
      "   Time: 112.51343560218811\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 构造一个噪声图像,这样比直接用白噪声快一点\n",
    "#initial_image = utils.generate_noise_image(content_image, IMAGE_HEIGHT, IMAGE_WIDTH, NOISE_RATIO)\n",
    "initial_image =  np.random.normal(0,0.1,size =(1,IMAGE_HEIGHT, IMAGE_WIDTH,3))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #初始化变量创建保存器和summary的writer\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(loc_dir + '/result',sess.graph)\n",
    "    skip_step = 1\n",
    "    \n",
    "    #构造检查点\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(loc_dir + '/checkpoints/checkpoint'))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "    sess.run(input_image.assign(initial_image)) #这里要明白为什么要这样做\n",
    "    initial_step = model['global_step'].eval()#得到全局变量的值\n",
    "    \n",
    "    start_time = time.time()#用于计算运行时间\n",
    "    for index in range(initial_step, STEPS):\n",
    "        #从慢到快的记录数据\n",
    "        if index >= 5 and index < 20:\n",
    "            skip_step = 10\n",
    "        elif index >= 20:\n",
    "            skip_step = 20\n",
    "        sess.run(model['optimizer'])# 计算优化方程\n",
    "        #下面是用于获取图像、记录检查点和打印展示信息\n",
    "        if (index + 1) % skip_step == 0:\n",
    "            gen_image, total_loss, summary = sess.run([input_image, model['total_loss'],model['summary_op']])\n",
    "            gen_image = gen_image + MEAN_PIXELS #还原图像\n",
    "            writer.add_summary(summary, global_step=index)\n",
    "            print('Step {}\\n   Sum: {:5.1f}'.format(index + 1, np.sum(gen_image)))\n",
    "            print('   Loss: {:5.1f}'.format(total_loss))\n",
    "            print('   Time: {}'.format(time.time() - start_time))\n",
    "            #计算时间\n",
    "            start_time = time.time()\n",
    "            #filename = loc_dir + '/outputs/%d.png'%(index)\n",
    "            filename = loc_dir+'/transfer_pic/' + '%d.png'%(index)\n",
    "            save_image(filename, gen_image)\n",
    "            if (index + 1) % 20 == 0:\n",
    "                saver.save(sess, loc_dir +'/checkpoints/style_transfer', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
